{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2 as cv\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result, process_mmdet_results)\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 导入可视化工具包 matplotlib，并让绘制的图像嵌入在 notebook 中\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 定义可视化图像函数，输入图像路径，可视化图像\n",
    "def show_img_from_path(img_path):\n",
    "    '''opencv 读入图像，matplotlib 可视化格式为 RGB，因此需将 BGR 转 RGB，最后可视化出来'''\n",
    "    img = cv2.imread(img_path)\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.show()\n",
    "    \n",
    "# 定义可视化图像函数，输入图像 array，可视化图像\n",
    "def show_img_from_array(img):\n",
    "    '''输入 array，matplotlib 可视化格式为 RGB，因此需将 BGR 转 RGB，最后可视化出来'''\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pose_config = 'mmpose/configs/res101_pig.py'\n",
    "pose_checkpoint = 'mmpose/work_dirs/resnet101_pig/epoch_190.pth'\n",
    "det_config = 'mmdetection/configs/yolox/yolox_s_8x8_300e_coco.py'\n",
    "det_checkpoint = 'mmdetection/work_dirs/yolox_s_300e_coco/best_bbox_mAP_epoch_295.pth'\n",
    "\n",
    "# initialize pose model\n",
    "pose_model = init_pose_model(pose_config, pose_checkpoint,device='cuda:0')\n",
    "# initialize detector\n",
    "det_model = init_detector(det_config, det_checkpoint, device='cuda:0')\n",
    "point_dic=pose_model.cfg.dataset_info.keypoint_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_dic=pose_model.cfg.dataset_info.skeleton_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenbang/anaconda3/envs/mmlab/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "img = '/home/zhenbang/project/openmmlab/mmpose/data/pig_pose/images/p121_6933.jpg'\n",
    "\n",
    "# inference detection\n",
    "mmdet_results = inference_detector(det_model, img)\n",
    "\n",
    "# extract person (COCO_ID=1) bounding boxes from the detection results\n",
    "pig_results = process_mmdet_results(mmdet_results, cat_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=cv.imread(img).shape\n",
    "thr=w/5\n",
    "l=int(thr)\n",
    "r=int(w-thr)\n",
    "pig_results = [{'bbox': np.array([l, 0,r-l, h])}]\n",
    "\n",
    "# inference pose\n",
    "pose_results, returned_outputs = inference_top_down_pose_model(\n",
    "    pose_model,\n",
    "    img,\n",
    "    pig_results,\n",
    "    # bbox_thr=0.8,\n",
    "    format='xyxy',\n",
    "    dataset=pose_model.cfg.data.test.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "points=pose_results[0]['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=list()\n",
    "for i in range(4):\n",
    "    l=list()\n",
    "    l.append(points[0][:2])\n",
    "    l.append(points[i*4+1:i*4+5,:2])\n",
    "    link.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_points=list()\n",
    "for it in link:\n",
    "    l=list()\n",
    "    for i in range(3):\n",
    "        l.append(np.append(it[0],it[1][i]))\n",
    "        l.append(np.append(it[1][i+1],it[1][i]))\n",
    "    l.append(np.append(it[1][0],it[1][1]))\n",
    "    l.append(np.append(it[1][2],it[1][1]))\n",
    "    l.append(np.append(it[1][1],it[1][2]))\n",
    "    l.append(np.append(it[1][3],it[1][2]))\n",
    "    angle_points.append(l)\n",
    "angle_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def angle(v1, v2):\n",
    "  dx1 = v1[2] - v1[0]\n",
    "  dy1 = v1[3] - v1[1]\n",
    "  dx2 = v2[2] - v2[0]\n",
    "  dy2 = v2[3] - v2[1]\n",
    "  angle1 = math.atan2(dy1, dx1)\n",
    "  angle1 = int(angle1 * 180/math.pi)\n",
    "  # print(angle1)\n",
    "  angle2 = math.atan2(dy2, dx2)\n",
    "  angle2 = int(angle2 * 180/math.pi)\n",
    "  # print(angle2)\n",
    "  if angle1*angle2 >= 0:\n",
    "    included_angle = abs(angle1-angle2)\n",
    "  else:\n",
    "    included_angle = abs(angle1) + abs(angle2)\n",
    "  return included_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in angle_points:\n",
    "    for i in range(5):\n",
    "\n",
    "        print(angle(it[i*2],it[i*2+1],True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles=list()\n",
    "for it in angle_points:\n",
    "    l=list()\n",
    "    for i in range(6):\n",
    "        l.append(angle(it[i*2],it[i*2+1]))\n",
    "    angles.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_for_model(result):\n",
    "    points=result['keypoints']\n",
    "    link=list()\n",
    "    for i in range(4):\n",
    "        l=list()\n",
    "        l.append(points[0][:2])\n",
    "        l.append(points[i*4+1:i*4+5,:2])\n",
    "        link.append(l)\n",
    "\n",
    "    angle_points=list()\n",
    "    for it in link:\n",
    "        l=list()\n",
    "        for i in range(3):\n",
    "            l.append(np.append(it[0],it[1][i]))\n",
    "            l.append(np.append(it[1][i+1],it[1][i]))\n",
    "        l.append(np.append(it[1][0],it[1][1]))\n",
    "        l.append(np.append(it[1][2],it[1][1]))\n",
    "        l.append(np.append(it[1][1],it[1][2]))\n",
    "        l.append(np.append(it[1][3],it[1][2]))\n",
    "        angle_points.append(l)\n",
    "        \n",
    "    angles=list()\n",
    "    for it in angle_points:\n",
    "        l=list()\n",
    "        for i in range(5):\n",
    "                l.append(angle(it[i*2],it[i*2+1]))\n",
    "        angles.append(l)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[145, 134, 152, 160, 191],\n",
       " [136, 155, 180, 189, 200],\n",
       " [250, 251, 257, 193, 198],\n",
       " [228, 245, 241, 205, 187]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_angles\n",
    "get_angles(pose_results[0]['keypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[145, 134, 152, 160, 191],\n",
       " [136, 155, 180, 189, 200],\n",
       " [250, 251, 257, 193, 198],\n",
       " [228, 245, 241, 205, 187]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_for_model(pose_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_result = vis_pose_result(\n",
    "    pose_model,\n",
    "    img,\n",
    "    pose_results,\n",
    "    dataset=pose_model.cfg.data.test.type,\n",
    "    show=False)\n",
    "show_img_from_array(vis_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429919fe5eee10fa3db4376c75d0431aac4ee64633f3fde6de3e71a7b7c5c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
